{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dev-Matching.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"mount_file_id":"1oxxj9p4YvYbuagZWZr2hPEZvwe8vYhFD","authorship_tag":"ABX9TyMBMdKiSRoiA8wMJcIY58Td"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9brNEH2WFVGy"},"source":["#### google colab 환경에서 진행하였습니다."]},{"cell_type":"code","metadata":{"id":"8V6rsSrmIaQf"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OUGoyjCQFt1Q"},"source":["# dataset unzip & library install"]},{"cell_type":"code","metadata":{"id":"gPhqRx4g-FwU"},"source":["# !unzip /content/drive/MyDrive/train.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3Uo0s1y-FuQ"},"source":["# !unzip /content/drive/MyDrive/test.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D0jYrglv-FsD"},"source":["# !pip install timm\n","# !pip install albumentations==0.4.6\n","# !pip install adamp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2SBOAWI1-Fpw"},"source":["# !pip install opencv-python\n","# !apt-get install libgl1-mesa-glx -y\n","# !pip install seaborn"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aWpJ66fYFxkC"},"source":["# EDA (Exploratory Data Analysis)"]},{"cell_type":"code","metadata":{"id":"ljrLyHrsH41u"},"source":["import os\n","import sys\n","from glob import glob\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from PIL import Image\n","from tqdm.notebook import tqdm\n","from time import time\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pn3e2e5CH4zo"},"source":["class cfg:\n","    data_dir = '/content'\n","    tr_dir = f'{data_dir}/train'\n","    te_dir = f'{data_dir}/test'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8mPYmJFH4xm"},"source":["classes = ['dog', 'elephant', 'giraffe','guitar','horse','house','person']\n","num2class = {v: k for v, k in enumerate(classes)}\n","class2num = {k: v for v, k in enumerate(classes)}\n","print(num2class)\n","print(class2num)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Btn6-4L3H4v5"},"source":["d = dict(label=[], class_name=[], path=[])\n","img_info = dict(heights=[], widths=[], means=[], stds=[])\n","for num in range(7):\n","    class_name = num2class[num]\n","    class_dir = os.path.join(cfg.tr_dir, class_name)\n","    filename = os.listdir(class_dir)\n","    \n","    for img_name in filename:\n","        path = os.path.join(class_dir, img_name)\n","        img = np.array(Image.open(path))\n","        h, w, _ = img.shape\n","        d['label'].append(class2num[class_name])\n","        d['class_name'].append(class_name)\n","        d['path'].append(path)\n","        \n","        img_info['heights'].append(h)\n","        img_info['widths'].append(w)\n","        img_info['means'].append(img.mean(axis=(0,1)))\n","        img_info['stds'].append(img.std(axis=(0,1)))\n","\n","tr_df = pd.DataFrame(data=d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nxy9ShtQH4tv"},"source":["print(f'Total number of images is {len(tr_df)}')\n","\n","print(f'Minimum height for dataset is {np.min(img_info[\"heights\"])}')\n","print(f'Maximum height for dataset is {np.max(img_info[\"heights\"])}')\n","print(f'Average height for dataset is {int(np.mean(img_info[\"heights\"]))}')\n","print(f'Minimum width for dataset is {np.min(img_info[\"widths\"])}')\n","print(f'Maximum width for dataset is {np.max(img_info[\"widths\"])}')\n","print(f'Average width for dataset is {int(np.mean(img_info[\"widths\"]))}')\n","\n","print(f'RGB Mean: {np.mean(img_info[\"means\"], axis=0) / 255.}')\n","print(f'RGB Standard Deviation: {np.mean(img_info[\"stds\"], axis=0) / 255.}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uG07TBiJH4rm"},"source":["# data\n","tr_df.groupby(['class_name']).count()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BQu3MyxHGSEh"},"source":["# Model Training & Inference"]},{"cell_type":"code","metadata":{"id":"fVWE0MynH4pt"},"source":["from glob import glob\n","from sklearn.model_selection import StratifiedKFold\n","import cv2\n","import torch\n","from torch import nn\n","import os\n","import random\n","import torchvision\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import math\n","import sys\n","import copy\n","\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data.sampler import SequentialSampler, RandomSampler\n","from torch.cuda.amp import autocast, GradScaler\n","from torch.nn.modules.loss import _WeightedLoss\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import _LRScheduler\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","import timm\n","\n","import sklearn\n","import warnings\n","import joblib\n","from sklearn import metrics\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","\n","from adamp import AdamP\n","\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","# hyper parameter setting\n","class CFG:\n","    seed = 2021\n","    num_workers = 4\n","    \n","    img_size = 227\n","    \n","    fold_num = 5\n","    epoch = 30\n","    batch_size = 32\n","    lr = 1e-4\n","    \n","    T_0=10\n","    T_max=10\n","    min_lr = 1e-7\n","    scheduler = 'CosineAnnealingWarmRestarts'\n","    \n","    optimizer = 'AdamP'\n","    \n","    model = 'tf_efficientnet_b3_ns'\n","    \n","    pretrained = True\n","    mean= [0.5556861, 0.50740065, 0.45690217]\n","    std= [0.22876642, 0.21754766, 0.22090458]\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBbjNcw4H4lr"},"source":["# 데이터 불균형 문제를 해결하기 위해 F1 loss와 Cross entropy loss를 결합\n","class CustomLoss(nn.Module):\n","    def __init__(self, classes=7, epsilon=1e-7):\n","        super().__init__()\n","        self.classes = classes\n","        self.epsilon = epsilon\n","    \n","    def forward(self, y_pred, y_true):\n","        assert y_pred.ndim == 2\n","        assert y_true.ndim == 1\n","        \n","        ce_loss =  nn.functional.cross_entropy(y_pred, y_true)\n","        f1_loss = self._f1_loss(y_pred, y_true)\n","\n","        return f1_loss + ce_loss\n","\n","    def _f1_loss(self, y_pred, y_true):\n","        y_true = F.one_hot(y_true, self.classes).to(torch.float32)\n","        y_pred = F.softmax(y_pred, dim=1)\n","\n","        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n","        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n","        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n","\n","        precision = tp / (tp + fp + self.epsilon)\n","        recall = tp / (tp + fn + self.epsilon)\n","\n","        f1 = 2 * (precision * recall) / (precision + recall + self.epsilon)\n","        f1 = f1.clamp(min=self.epsilon, max=1 - self.epsilon)\n","        \n","        f1_loss = 1 - f1.mean()\n","        return f1_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9v4C0GVaH4ju"},"source":["class MyDataset(Dataset):\n","    def __init__(self, df, transforms=None, output_label=True):\n","        super().__init__()\n","        self.df = df.copy()\n","        self.transforms = transforms\n","        self.output_label = output_label\n","    \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, index: int):\n","        if self.output_label:\n","            target = self.df[index][0]\n","        \n","        path = self.df[index][2]\n","        \n","        img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n","        \n","        if self.transforms:\n","            img = self.transforms(image=img)['image']\n","            \n","        if self.output_label:\n","            return img, target\n","        else:\n","            return img "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3n599SdH4hl"},"source":["# Data Augmentation\n","\n","def get_train_transforms():\n","      return A.Compose([\n","                      A.HueSaturationValue(), # 색상(Hue), 채도(Saturation), 명도(Value) 변경\n","                      A.OneOf([\n","                                A.OpticalDistortion(p=0.4), # 광학적 왜곡\n","                                A.GridDistortion(p=0.2),    # 격자 왜곡\n","                                A.IAAPiecewiseAffine(p=0.4),# affine transform\n","                      ], p=0.5),\n","                      A.RandomBrightnessContrast(brightness_limit=(-0.3, 0.3), contrast_limit = (-0.1, 0.1), p = 0.5), # 밝기 대비\n","                      A.Normalize(mean=CFG.mean, std=CFG.std, max_pixel_value=255.0, p = 1.0),\n","                      ToTensorV2(p=1.0)\n","                      ], p = 1.)\n","\n","def get_valid_transforms():\n","      return A.Compose([\n","                      A.Normalize(mean=CFG.mean, std=CFG.std, max_pixel_value=255.0, p=1.0),\n","                      ToTensorV2(p = 1.0),\n","                      ], p = 1.)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a4dl6CsLH4fm"},"source":["# data loader setting\n","\n","def prepare_dataloader(df, train_index, valid_index):\n","    \n","    train_ = df.values[train_index]\n","    valid_ = df.values[valid_index]\n","    \n","    train_ds = MyDataset(train_, transforms=get_train_transforms(), output_label=True)\n","    valid_ds = MyDataset(valid_, transforms=get_valid_transforms(), output_label=True)\n","    \n","    train_loader = torch.utils.data.DataLoader(\n","        train_ds,\n","        batch_size=CFG.batch_size,\n","        pin_memory=True,\n","        drop_last=False,\n","        shuffle=True,\n","        num_workers=CFG.num_workers,\n","    )\n","    val_loader = torch.utils.data.DataLoader(\n","        valid_ds,\n","        batch_size=CFG.batch_size,\n","        num_workers=CFG.num_workers,\n","        shuffle=False,\n","        pin_memory=True,\n","    )\n","    return train_loader, val_loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLF3N8Q3H4dr"},"source":["# pretrained model(tf_efficientnet_b3_ns)을 fine tuning을 하는 방식으로 학습\n","\n","class EffNetClassifier(nn.Module):\n","    def __init__(self, model_arch, n_class, pretrained=False):\n","        super().__init__()\n","        self.model = timm.create_model(model_arch, pretrained=pretrained)\n","        n_features = self.model.classifier.in_features\n","        self.model.classifier = nn.Linear(n_features, n_class)\n","        \n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZI2d8H4mH4bV"},"source":["# training\n","\n","def train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=None):\n","    model.train()\n","\n","    running_loss = None\n","    pbar = tqdm(enumerate(train_loader), total=len(train_loader), position=0, leave=True)\n","    for step, (imgs, image_labels) in pbar:\n","        imgs = imgs.to(device).float()\n","        image_labels = image_labels.to(device).long()\n","\n","        with autocast():\n","            image_preds = model(imgs.float())\n","            \n","            loss = loss_fn(image_preds, image_labels)\n","            \n","            scaler.scale(loss).backward()\n","\n","            if running_loss is None:\n","                running_loss = loss.item()\n","            else:\n","                running_loss = running_loss * .99 + loss.item() * .01\n","\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad() \n","\n","            description = f'epoch {epoch} loss: {running_loss:.4f}'\n","            \n","            pbar.set_description(description)\n","                \n","    if scheduler is not None:\n","        scheduler.step()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RA4v8sY4H4ZV"},"source":["# validation measuring\n","\n","def valid_one_epoch(epoch, model, loss_fn, val_loader, device):\n","    model.eval()\n","\n","    loss_sum = 0\n","    sample_num = 0\n","    image_preds_all = []\n","    image_targets_all = []\n","    \n","    pbar = tqdm(enumerate(val_loader), total=len(val_loader), position=0, leave=True)\n","    for step, (imgs, image_labels) in pbar:\n","        imgs = imgs.to(device).float()\n","        image_labels = image_labels.to(device).long()\n","        \n","        image_preds = model(imgs)\n","\n","        image_preds_all += [torch.argmax(image_preds, 1).detach().cpu().numpy()]\n","        image_targets_all += [image_labels.detach().cpu().numpy()]\n","        \n","        loss = loss_fn(image_preds, image_labels)\n","        \n","        loss_sum += loss.item()*image_labels.shape[0]\n","        sample_num += image_labels.shape[0]  \n","\n","        if ((step + 1) % 1 == 0) or ((step + 1) == len(val_loader)):\n","            description = f'epoch {epoch} loss: {loss_sum/sample_num:.4f}'\n","            pbar.set_description(description)\n","    \n","    image_preds_all = np.concatenate(image_preds_all)\n","    image_targets_all = np.concatenate(image_targets_all)\n","    accuracy = (image_preds_all==image_targets_all).mean()\n","    f1 = f1_score(image_preds_all, image_targets_all, average='macro')\n","    print('validation multi-class accuracy = {:.4f}, f1 score = {:.4f}'.format(accuracy, f1))\n","    \n","    return accuracy, f1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GtR3dq7TH4St"},"source":["class TestDataset(Dataset):\n","    def __init__(self, img_paths, transform):\n","        self.img_paths = img_paths\n","        self.transform = transform\n","\n","    def __getitem__(self, index):\n","        path = self.img_paths[index]\n","        img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n","\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img\n","\n","    def __len__(self):\n","        return len(self.img_paths)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eu9Ci7rQH4Qe"},"source":["# test dataset setting\n","\n","test_img_root = f'{cfg.te_dir}/0'  # 테스트 이미지 폴더의 경로\n","submission = pd.read_csv('/content/drive/MyDrive/test_answer_sample_.csv')\n","\n","# Test Dataset 클래스 객체를 생성하고 DataLoader를 만듭니다.\n","image_paths = [os.path.join(test_img_root, img_id) for img_id in os.listdir(test_img_root)]\n","\n","test_dataset = TestDataset(image_paths, transform=get_valid_transforms())\n","\n","test_loader = DataLoader(\n","    test_dataset,\n","    shuffle=False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZaN97bJH1-3"},"source":["seed_everything(CFG.seed)\n","\n","oof_pred = None\n","\n","# label별 분포를 고려하여 5개의 fold로 나누어 학습 \n","kfold = StratifiedKFold(n_splits=CFG.fold_num)\n","for fold , (train_index, valid_index) in enumerate(kfold.split(tr_df, tr_df[\"label\"])):\n","    print('Training with {} started'.format(fold))\n","    \n","    train_loader, val_loader = prepare_dataloader(tr_df, train_index, valid_index)\n","    \n","    device = CFG.device\n","    model = EffNetClassifier(CFG.model, tr_df.label.nunique(), pretrained=True).to(device)\n","    \n","    optimizer = AdamP(model.parameters(), lr=CFG.lr)\n","        \n","    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr ,last_epoch=-1)     \n","    \n","    loss_fn = CustomLoss().to(device)\n","\n","    scaler = GradScaler()\n","    \n","    best_accuracy = 0\n","    best_f1 = 0\n","    best_epoch = 0\n","    stop_count = 0\n","    for epoch in range(CFG.epoch):\n","        train_one_epoch(epoch, model, loss_fn, optimizer, train_loader, device, scheduler=scheduler)\n","\n","        with torch.no_grad():\n","            epoch_accuracy, epoch_f1 = valid_one_epoch(epoch, model, loss_fn, val_loader, device)\n","\n","        if epoch_f1 > best_f1:\n","            stop_count = 0\n","            best_state_dict = copy.deepcopy(model.state_dict())\n","            \n","            best_f1 = epoch_f1\n","            best_epoch = epoch\n","            print('The model is saved!')\n","        else:\n","            # early stopping\n","            stop_count += 1\n","            if stop_count > 5:\n","                break\n","    \n","    # 저장되어 있는 best model을 load 해옵니다.\n","    model.load_state_dict(best_state_dict)\n","    \n","    # 각 fold에서 생성된 모델을 사용해 Test 데이터를 예측합니다.\n","    all_predictions = []\n","    with torch.no_grad():\n","        for images in test_loader:\n","            images = images.to(device)\n","            \n","            # Test Time Augmentation\n","            pred = model(images) / 2 # 원본 이미지를 예측하고\n","            pred += model(torch.flip(images, dims=(2, 3))) / 2 # flip으로 뒤집어 예측합니다. \n","            all_predictions.extend(pred.cpu().numpy())\n","\n","        fold_pred = np.array(all_predictions)\n","    \n","    if oof_pred is None:\n","        oof_pred = fold_pred / CFG.fold_num\n","    else:\n","        oof_pred += fold_pred / CFG.fold_num\n","        \n","    del model, optimizer, train_loader, val_loader, scaler, scheduler\n","    torch.cuda.empty_cache()\n","    print('Best Accuracy: {} in epoch {}'.format(best_f1, best_epoch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tA2cxfiOrBpP"},"source":["oof_pred = np.argmax(oof_pred, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EFCb0EDUzFb"},"source":["# test dataset 정렬\n","\n","def path2id(image_path):\n","    return int(image_path.split('/')[-1][:-4])\n","\n","id_list = list(map(path2id,image_paths))\n","\n","predictions = []\n","for i, pred in zip(id_list,oof_pred):\n","    predictions.append((i, pred))\n","predictions.sort(key=lambda x:x[0])\n","\n","predictions = np.array([pred for i, pred in predictions])\n","\n","submission['answer value'] = predictions\n","submission.to_csv('/content/drive/MyDrive/final_submission.csv', index=False)\n","print('test inference is done!')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DaseDuejTnqm"},"source":[],"execution_count":null,"outputs":[]}]}